{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/LAION-AI/aesthetic-predictor/blob/main/asthetics_predictor.ipynb","timestamp":1717555462225}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Prepare"],"metadata":{"id":"bNngcd8UAOma"}},{"cell_type":"code","source":["# mount google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0AueVb_WGzH","executionInfo":{"status":"ok","timestamp":1717556543298,"user_tz":420,"elapsed":16214,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}},"outputId":"25008f60-c9be-46a6-a352-bbc0e04f7ab9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/cs231n_final_project/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rG-UCPnpWDDQ","executionInfo":{"status":"ok","timestamp":1717556551126,"user_tz":420,"elapsed":2,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}},"outputId":"60bac779-c817-42f7-ba6c-649ed28b05db"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cs231n_final_project\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kAC3PZmiPPo","outputId":"bc5af7e9-b292-4be8-f928-33d652d5fd0a","executionInfo":{"status":"ok","timestamp":1717556426726,"user_tz":420,"elapsed":70282,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting open-clip-torch\n","  Downloading open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.18.0+cu121)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2024.5.15)\n","Collecting ftfy (from open-clip-torch)\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (4.66.4)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.23.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (3.20.3)\n","Collecting timm (from open-clip-torch)\n","  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9.0->open-clip-torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->open-clip-torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (2.31.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->open-clip-torch) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, open-clip-torch\n","Successfully installed ftfy-6.2.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 open-clip-torch-2.24.0 timm-1.0.3\n"]}],"source":["!pip install open-clip-torch"]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from os.path import expanduser  # pylint: disable=import-outside-toplevel\n","from urllib.request import urlretrieve  # pylint: disable=import-outside-toplevel\n","def get_aesthetic_model(clip_model=\"vit_l_14\"):\n","    \"\"\"load the aethetic model\"\"\"\n","    home = expanduser(\"~\")\n","    cache_folder = home + \"/.cache/emb_reader\"\n","    path_to_model = cache_folder + \"/sa_0_4_\"+clip_model+\"_linear.pth\"\n","    if not os.path.exists(path_to_model):\n","        os.makedirs(cache_folder, exist_ok=True)\n","        url_model = (\n","            \"https://github.com/LAION-AI/aesthetic-predictor/blob/main/sa_0_4_\"+clip_model+\"_linear.pth?raw=true\"\n","        )\n","        urlretrieve(url_model, path_to_model)\n","    if clip_model == \"vit_l_14\":\n","        m = nn.Linear(768, 1)\n","    elif clip_model == \"vit_b_32\":\n","        m = nn.Linear(512, 1)\n","    else:\n","        raise ValueError()\n","    s = torch.load(path_to_model)\n","    m.load_state_dict(s)\n","    m.eval()\n","    return m\n","\n","amodel= get_aesthetic_model(clip_model=\"vit_l_14\")\n","amodel.eval()\n","\n","import torch\n","from PIL import Image\n","import open_clip\n","model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')"],"metadata":{"id":"eHNMKf0DlYTw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717556463324,"user_tz":420,"elapsed":36604,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}},"outputId":"b15078a8-a90c-4579-94ed-488e8a4cbc13"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 933M/933M [00:11<00:00, 80.3MiB/s]\n"]}]},{"cell_type":"markdown","source":["## Run"],"metadata":{"id":"kBu_5UDhAREh"}},{"cell_type":"code","source":["import numpy as np\n","\n","movies = ['frozen', 'spirited_away', 'harry_potter', 'marnie']"],"metadata":{"id":"YfAWaJIyUQYo","executionInfo":{"status":"ok","timestamp":1717556476229,"user_tz":420,"elapsed":325,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["all_baselines = []\n","all_results = []\n","for movie in movies:\n","  baseline_scores = np.zeros(3)\n","  result_scores = np.zeros(3)\n","  for i in range(3):\n","    image = preprocess(Image.open(f\"{movie}/baseline/output/images/frames/{i * 15}.png\")).unsqueeze(0)\n","    result_image = preprocess(Image.open(f\"{movie}/result/output/images/frames/{i * 15}.png\")).unsqueeze(0)\n","    with torch.no_grad():\n","      image_features = model.encode_image(image)\n","      image_features /= image_features.norm(dim=-1, keepdim=True)\n","      prediction = amodel(image_features)\n","      baseline_scores[i] = prediction\n","\n","      result_features = model.encode_image(result_image)\n","      result_features /= result_features.norm(dim=-1, keepdim=True)\n","      result_prediction = amodel(result_features)\n","      result_scores[i] = result_prediction\n","  print(f\"Baseline scores for {movie}: {np.mean(baseline_scores)}\")\n","  all_baselines.append(np.mean(baseline_scores))\n","  print(f\"Result scores for {movie}: {np.mean(result_scores)}\")\n","  all_results.append(np.mean(result_scores))\n","print(f\"Average baseline score: {np.mean(all_baselines)}\")\n","print(f\"Average result score: {np.mean(all_results)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaJHz-BWUWOu","executionInfo":{"status":"ok","timestamp":1717559490205,"user_tz":420,"elapsed":66661,"user":{"displayName":"emily zhang","userId":"11504737095468598065"}},"outputId":"3ce2ad8c-b9bf-4a34-b9f8-fd48194832a5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline scores for frozen: 5.9680399894714355\n","Result scores for frozen: 5.691035906473796\n","Baseline scores for spirited_away: 6.266530195871989\n","Result scores for spirited_away: 6.1663510004679365\n","Baseline scores for harry_potter: 6.090071042378743\n","Result scores for harry_potter: 6.127197901407878\n","Baseline scores for marnie: 6.196268876393636\n","Result scores for marnie: 6.91407585144043\n","Average baseline score: 6.130227526028951\n","Average result score: 6.22466516494751\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"afBYVbhuU6-Q"},"execution_count":null,"outputs":[]}]}